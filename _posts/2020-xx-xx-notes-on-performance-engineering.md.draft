what is more important than performance?
compatibility
functionality
reliability
correctness
maintainability
robustness
clarity
modularity
testability
debuggability
portability
usability

performance is the currency of computing. you can buy needed properties with
performance.

Problem of not knowing performance engineering:
https://news.ycombinator.com/item?id=21929829


--------------

software performance engineering was common in the early days since machine
resources were limited.

Premature optimization is the root of all evil. [K79]

More computing sins are committed in the name of efficiency (without necessarily achieving it) than for any other single reason — including blind stupidity. [W79]

The First Rule of Program Optimization: Don’t do it. The Second Rule of Program Optimization — For experts only: Don’t do it yet. [J88]

scaling/power/job/ all getting hotter

but still hard

fundamentally: How can we write software to utilize modern hardware efficiently?

--------------------
What is performance?
computing: GFLOPs
memory: throughput (bandwidth)
disk: size/speed
---------------------

use time and total flops to compute proportion to the peak performance.
sample sort example
rootline model
GPU performance guide (occupancy vs. ILP)
---------------------

matmul example:
4096*4096, 4096*4096
py: 6hr, java: 46min, C: 19min
compiled directly to machine code > byte-code, then interpreted and JIT compiled
into machine code > interpreted

cache hits/misses
spatial locality/temporal locality

compiler opt:
-O1, -O2, -O3

autotune, search and optimization, treat it like black-box:
like JIT, first try all, data-driven, find the best, then amortize the tried
time by using the best for frequently loaded cases.

algorithmic:
find vertex cover (wechat red packet)
vgg/resnet/depthwise/octave conv
hybrid allreduce

multi-core, many-core parallelism

parallel outer loops rather than inner loops

---------------------------------------------

analyzing memory accesses:
try different blocks and tiles (TVM)

recursive parallel (divide and conquer)

SIMD

intel MKL 40% peak perf
---------------------------------------

GPU matmul:
even faster.
---------------------------------------
Bentley's Rules
Writing Efficient Programs
how to reduce work

Data Structure:
packing and unpacking:
less space/less mem fetch/more work
VID mapping
bitfield (pbrt, date example)

augmentation:
bcsr
linked list

pre-computed:
runtime pre-computed
compile-time initialization
example: lookup table, SAT, Cuthill–McKee, DP, memorization
metaprogramming (template tail-recursive, macro, etc.)

caching:
temporal locality

space locality:
memory access pattern

sparsity:
the fastest way to compute is not to compute at all.
using CSR for spmv

Logic: (for common programs, optimizations include in gcc/clang
but for NN models, you need to specify it yourself:
what dl frameworks are doing, still corner cases)
constant folding and propagation.

CSE common subexpression elimination: kinda like caching

algebraic identity: DES

short circuiting: directional BFS
occlude detection using hierarchical spatial tree data structure

Loop:
hoisting: invariant to outside
unrolling: ILP, beware of register spill, instruction chache miss

----------------------------------------
communication:
do not cause stall. (reorder, fusion)
do not waste bandwidth. (fusion, hybrid allreduce)

Cycle:

baseline
find bottleneck
try alternatives
set the improved version to new baseline
------------------------------------------
load balancing
for irregular problem
merge-path, two-phase
persistent thread work stealing
distribued rendering: kd-tree, octree etc.
------------------------------------------
Also, know when to stop.
it's an art of tradeoff. Getting 50% is good, getting 80% is excellent.
getting 95% usually costs too much effort, unless the return matches.
getting 100%? Show me how.

My mentor:
John Owens
Sean Baxter
Scott Gray

================================================
---
layout: post
title: Why every programmer should (re)learn performance engineering?
description: I have been doing performance engineering for all my professional life. Mostly on the GPU, but also touched other directions. This article is a summary of things I learned along the way as well as inspirations from multiple sources.
lang: en
---

> Premature optimization is the root of all evil. ---D. E. Knuth [K79]

Motivation
----------

I started programming early and the first field of computer science I really fell in love with and devoted a lot of time and efforts was computer graphics. So needless to say, performance engineering has fulfilled my most professional life. After all, real-time rendering is all about real-time, latency optimization. And later on when I switched my focus to high performance computing and GPU computing, performance became even more crutial.

Back in 90s and 2000s, being a good coder implies that she must know a lot about performance engineering. Large part of the reason was due to the constrained computing resource and the lack of advanced tools. Whereas in the current time, the beginning of a new decade, open source tools and easily available computing resource (be it on the cloud or locally) are lowering the threshold of doing computer science research every year. In an ocean of libraries and nodes with accelerators like GPU, I see a trend for younger generation of computer science researchers to have less and less knowledge of performance engineering. Or, they take high performance as a guarantee, a free lunch, and play with their model without much consideration.

As a programmer who spent most of his time doing performance optimization and high performance & parallel computing, I think it is necessary to reclaim the importance of performance engineering and share some of my learned experiences as well as some of the biggest insprirations I used to form my current view on performance engineering.

Overview
--------
First of all, I should say that most of the content of this post is just the summary of the first two lectures of [MIT 6.172: Performance Engineering for Software Systems](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-172-performance-engineering-of-software-systems-fall-2018/index.htm), plus my own experiences and some extension to GPUs. So if you want to learn about performance engineering systematically, I highly recommend you to go directly to that course's home page.

I still remember the title of the first chapter of Michael Abrash's Graphics Programming Black Book: __The Best Optimizer Is between Your Ears__. I totally agree that your brain is much much more important than compiler tools and hardware accelerators. But let's step back a bit and first clarify a question: What is performance? 
